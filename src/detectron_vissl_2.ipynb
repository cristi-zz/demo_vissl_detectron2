{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa96aef4-6829-466e-9534-245b91bbaf5a",
   "metadata": {},
   "source": [
    "# Experiment to see if VISSL helps with segmentation\n",
    "\n",
    "1) Take a ResNet from torchvision and SSL with some pretext on balloons for few iterations. Export model for Detectron2\n",
    "2) Take a ResNet from torchvision and SSL with some pretext on balloons for MANY iterations. Export model for Detectron2\n",
    "3) Take same ResNet from torchvision, train for x epocs on balloons, evaluate on balloons\n",
    "4) Take the ResNet from SSL(1), train for x epocs on balloons, evaluate on balloons\n",
    "5) Take the ResNet from SSL(2), train for x epocs on balloons, evaluate on balloons\n",
    "\n",
    "Ideally, 3 ~= 4 and 4 > 5. But it will be nice if 4 > 5 and 3 > 4. If not . . .\n",
    "\n",
    "## Results\n",
    "**SPOILER ALERT**\n",
    "\n",
    "Performance of torcvhision backbone is less than the performance of model_zoo backbone. Something like AP=80 versus 50. \n",
    "\n",
    "The performance of slightly SSL trained torchvision backbone is slightly worse than original one\n",
    "\n",
    "The performance of intensly SSL trained torchvision backbone is **much worse** than original one. Guesses about why, in blog post."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd82da3b-22ef-44c6-b81a-72148add4002",
   "metadata": {},
   "source": [
    "### Some path setup and download pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7471408-b7f6-4061-aabf-4e87dbfded56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Setup some constants and paths\n",
    "MODELS_FOLDER = Path(\"../models\")\n",
    "BALLONS_FOLDER = Path(\"../balloon\")\n",
    "\n",
    "ResNet_base_weights = \"resnet50-11ad3fa6.pth\"\n",
    "ResNet_light_ssl = \"res50_vissl_small_count.torch\"\n",
    "ResNet_large_ssl = \"res50_vissl_large_count.torch\"\n",
    "\n",
    "resnet_torchvision_fname = Path(MODELS_FOLDER) / \"resnet50-11ad3fa6.pth\"\n",
    "resnet_torchvision_url = \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\"\n",
    "resnet_tv2D2_fname = Path(MODELS_FOLDER) / \"resnet50-tv-D2.pkl\"\n",
    "    \n",
    "# These are rooky numbers. Feel free to bump them! Esp SSL_large_iter_count and D2_iter_count. But on my \"SOTA\" GTX 980Ti this is it.\n",
    "SSL_small_iter_count = 5\n",
    "SSL_large_iter_count = 10 \n",
    "D2_iter_count = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daf3375-4bc6-47d4-92bf-af3a39ddea47",
   "metadata": {},
   "source": [
    "# Get a torchvision ResNet50 checkpoint weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125c2119-eb70-4e9f-b1a1-ca077799caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(resnet_tv2D2_fname).exists():\n",
    "    # Download the torchvision weights\n",
    "    import requests\n",
    "    with requests.get(resnet_torchvision_url, stream=True) as r:\n",
    "        with open(resnet_torchvision_fname, 'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    # Convert to Detectron2\n",
    "    ! python convert-torchvision-to-d2.py {resnet_torchvision_fname} {resnet_tv2D2_fname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55a99bf-d374-4bf0-b700-0269f575672f",
   "metadata": {},
   "source": [
    "# ViSSL training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b696f10-86bb-4c1f-b05f-2ba7d2d333d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_balloons_config_for_vissl():\n",
    "    crt_path = Path.cwd()\n",
    "    configs_path = crt_path / \"configs\"/ \"config\"\n",
    "    configs_path.mkdir(exist_ok=True, parents=True)\n",
    "    init_file_path = crt_path / \"configs\" / \"__init__.py\"\n",
    "    with open(init_file_path, \"wt\") as f:\n",
    "        f.write(\"\")\n",
    "\n",
    "    dataset_catalog_js = crt_path / \"configs\" / \"config\" / \"dataset_catalog.json\"\n",
    "    dataset_catalog_js.unlink(missing_ok=True)\n",
    "\n",
    "    # We will override settings from command line, later\n",
    "    !wget -q -O configs/config/quick_1gpu_resnet50_simclr.yaml https://dl.fbaipublicfiles.com/vissl/tutorials/configs/quick_1gpu_resnet50_simclr.yaml\n",
    "\n",
    "    # https://vissl.readthedocs.io/en/v0.1.5/getting_started.html\n",
    "    dataset_name = \"balloons_train_full\"\n",
    "    json_data = {\n",
    "            dataset_name: {\n",
    "                \"train\": [os.path.join(BALLONS_FOLDER,\"trainmodel_name.parent\"), os.path.join(BALLONS_FOLDER,\"train/via_region_data.json\") ],\n",
    "            }\n",
    "        }\n",
    "    from vissl.utils.io import save_file\n",
    "    save_file(json_data, \"configs/config/dataset_catalog.json\")\n",
    "\n",
    "    # Run only once to register the config.\n",
    "    from vissl.data.dataset_catalog import VisslDatasetCatalog\n",
    "    if dataset_name not in VisslDatasetCatalog.list():\n",
    "        VisslDatasetCatalog.register_data(name=\"balloons_train_full\", data_dict=json_data[\"balloons_train_full\"])\n",
    "    print(f\"Known datasets: {VisslDatasetCatalog.list()}\")\n",
    "    print(VisslDatasetCatalog.get(\"balloons_train_full\"))\n",
    "\n",
    "def del_checkpoint_folder():\n",
    "    crt_path = Path.cwd()\n",
    "    checpoint_dir = crt_path / \"checkpoints\"\n",
    "    shutil.rmtree(checpoint_dir, ignore_errors=True)\n",
    "\n",
    "\n",
    "def train_vissl_from_existing_model(model_file, no_epochs=5, data_limit=61, destination_D4_model_name=\"resnet50_fined_vissl2detectron.torch\",\n",
    "                                    checpoint_folder=\"./checkpoints\", model_folder=MODELS_FOLDER):\n",
    "    ! python3 run_distributed_engines.py hydra.verbose=true  \\\n",
    "      config.DATA.TRAIN.DATASET_NAMES=[balloons_train_full]  \\\n",
    "      config.DATA.TRAIN.DATA_SOURCES=[disk_folder]           \\\n",
    "      config.DATA.TRAIN.DATA_PATHS=[{BALLONS_FOLDER}] \\\n",
    "      config=quick_1gpu_resnet50_simclr                               \\\n",
    "      config.MODEL.WEIGHTS_INIT.PARAMS_FILE={model_file}   \\\n",
    "      config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=\"trunk._feature_blocks.\"   \\\n",
    "      config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=''   \\\n",
    "      config.MODEL.TRUNK.RESNETS.DEPTH=50                \\\n",
    "      config.CHECKPOINT.DIR={checpoint_folder}   \\\n",
    "      config.DATA.TRAIN.DATA_LIMIT={data_limit} \\\n",
    "      config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=4 \\\n",
    "      config.OPTIMIZER.num_epochs={no_epochs} \\\n",
    "      config.CHECKPOINT.CHECKPOINT_FREQUENCY=20 \\\n",
    "      config.TEST_EVERY_NUM_EPOCH=20 \\\n",
    "      config.DISTRIBUTED.NUM_PROC_PER_NODE=1 \\\n",
    "      config.CHECKPOINT.AUTO_RESUME=false \\\n",
    "      +config.TENSORBOARD_SETUP.USE_TENSORBOARD=false\n",
    "\n",
    "    chkpoints = Path(checpoint_folder)\n",
    "    model_names  = sorted(chkpoints.glob(\"model_final*.torch\"))\n",
    "    assert len(model_names) > 0, \"No model was exported. Maybe errors while training?\"\n",
    "    model_name = model_names[0]\n",
    "    out_vi2d2_name = model_folder / destination_D4_model_name\n",
    "    print(f\"Converting {model_name}  to {out_vi2d2_name}\")\n",
    "    ! python convert_vissl_to_detectron2.py                   \\\n",
    "        --input_model_file {model_name}                       \\\n",
    "        --output_model {out_vi2d2_name}   \\\n",
    "        --weights_type torch                                  \\\n",
    "        --state_dict_key_name classy_state_dict\n",
    "    # copy the stdout logs\n",
    "    src_log_file = Path(checpoint_folder) / \"stdout.json\"\n",
    "    dst_log_file = out_vi2d2_name.with_suffix(\".json\")\n",
    "    shutil.copyfile(src_log_file, dst_log_file)\n",
    "    \n",
    "generate_balloons_config_for_vissl()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720468ed-6c3d-463a-be70-c6ddd86d18e1",
   "metadata": {},
   "source": [
    "### Train with VISSL, a Resnet for one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68be915f-ccc7-46cd-bf38-0c3bd1407d5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del_checkpoint_folder()\n",
    "train_vissl_from_existing_model(str(MODELS_FOLDER / ResNet_base_weights), no_epochs=SSL_small_iter_count, data_limit=4, destination_D4_model_name=ResNet_light_ssl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da766d45-cd00-4bb5-9494-580025f48253",
   "metadata": {},
   "source": [
    "### Train with VISSL, a Resnet for some epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f88221-b8a9-48e3-ba63-a970ebb3198f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del_checkpoint_folder()\n",
    "train_vissl_from_existing_model(str(MODELS_FOLDER / ResNet_base_weights), no_epochs=SSL_large_iter_count, data_limit=61, destination_D4_model_name=ResNet_large_ssl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71acaae-a7b0-4ff6-b1b9-6481f209dbe8",
   "metadata": {},
   "source": [
    "# Detectron 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5c8f6f-3116-4832-a9e4-57749dbfd374",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import shutil\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111716e0-5cbd-4e7a-ace2-29ce14ab6f4c",
   "metadata": {},
   "source": [
    "## Setup balloon dataset for the Detectron2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967dc83e-05ea-40a0-825b-569085f15ee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "balloon_dir = BALLONS_FOLDER\n",
    "detecton_trian_limit = 20\n",
    "\n",
    "def get_balloon_dicts(img_dir, limit_data=0):\n",
    "    json_file = os.path.join(img_dir, \"via_region_data.json\")\n",
    "    with open(json_file) as f:\n",
    "        imgs_anns = json.load(f)\n",
    "\n",
    "    dataset_dicts = []\n",
    "    for idx, v in enumerate(imgs_anns.values()):\n",
    "        if idx > limit_data and limit_data > 0:\n",
    "            print(f\"Limiting data loading at idx {idx}\")\n",
    "            break\n",
    "        record = {}\n",
    "        \n",
    "        filename = os.path.join(img_dir, v[\"filename\"])\n",
    "        height, width = cv2.imread(filename).shape[:2]\n",
    "        \n",
    "        record[\"file_name\"] = filename\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "      \n",
    "        annos = v[\"regions\"]\n",
    "        objs = []\n",
    "        for _, anno in annos.items():\n",
    "            assert not anno[\"region_attributes\"]\n",
    "            anno = anno[\"shape_attributes\"]\n",
    "            px = anno[\"all_points_x\"]\n",
    "            py = anno[\"all_points_y\"]\n",
    "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
    "            poly = [p for x in poly for p in x]\n",
    "\n",
    "            obj = {\n",
    "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                \"segmentation\": [poly],\n",
    "                \"category_id\": 0,\n",
    "            }\n",
    "            objs.append(obj)\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts\n",
    "\n",
    "for d in [\"train\", \"val\"]:\n",
    "    try:\n",
    "        name = \"balloon_\" + d\n",
    "        DatasetCatalog.get(name)\n",
    "        del DatasetCatalog[name]\n",
    "    except Exception as e:\n",
    "        # print(f\"Exception while retrieving {name}: {e}\")\n",
    "        pass\n",
    "    \n",
    "for d in [\"train\", \"val\"]:\n",
    "    DatasetCatalog.register(\"balloon_\" + d, lambda d=d: get_balloon_dicts(os.path.join(balloon_dir, d), detecton_trian_limit if d == \"train\" else -1  ))  \n",
    "    MetadataCatalog.get(\"balloon_\" + d).set(thing_classes=[\"balloon\"])\n",
    "\n",
    "print(MetadataCatalog.get(\"balloon_train\"))\n",
    "print(MetadataCatalog.get(\"balloon_val\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97779693-a018-4a43-b9fa-143197f81542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detectron2_configuration(batch_size=2, num_iterations=4):\n",
    "    # Start from known ResNet segmentation setup:\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.DATASETS.TRAIN = (\"balloon_train\",)\n",
    "    cfg.DATASETS.TEST = (\"balloon_val\",)\n",
    "    cfg.DATALOADER.NUM_WORKERS = 4\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "    cfg.SOLVER.IMS_PER_BATCH = batch_size\n",
    "    cfg.SOLVER.BASE_LR = 0.0025  # pick a good LR\n",
    "    cfg.SOLVER.MAX_ITER = num_iterations    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "    cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "    return cfg\n",
    "\n",
    "def clear_output_folders(out_dir):\n",
    "    shutil.rmtree(out_dir, ignore_errors=True)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "def evaluate_model_on_balloons(cfg, predictor=None, model_file=\"model_final.pth\"):\n",
    "    print(f\"Evaluating {cfg.OUTPUT_DIR} {model_file}\")\n",
    "    meta_for_val = MetadataCatalog.get('balloon_val')\n",
    "    print(f\"Metadata for balloon_val dataset: {meta_for_val}\")\n",
    "    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, model_file)  \n",
    "    del_at_end = False\n",
    "    if predictor is None:\n",
    "        predictor = DefaultPredictor(cfg)\n",
    "        del_at_end = True\n",
    "    evaluator = COCOEvaluator(\"balloon_val\", output_dir=MODELS_FOLDER, allow_cached_coco=False)\n",
    "    val_loader = build_detection_test_loader(cfg, \"balloon_val\")\n",
    "    inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "    if del_at_end:\n",
    "        del predictor\n",
    "    del evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59913447-9960-4551-9700-24f79048b0a8",
   "metadata": {},
   "source": [
    "## Finetune genuine Detectron2 ResNet and evaluate on balloons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0ad31d-7118-4365-b679-359e4323b41b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg = get_detectron2_configuration(2, D2_iter_count)\n",
    "clear_output_folders(cfg.OUTPUT_DIR)\n",
    "# pprint.pprint(cfg)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "evaluate_model_on_balloons(cfg, trainer)\n",
    "del trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd94419-6f9c-4adb-9df1-905939c1e32d",
   "metadata": {},
   "source": [
    "## Finetune ResNet torchvision model and evaluate on Balloons\n",
    "\n",
    "1) Download the torchvision model\n",
    "2) Convert to Detectron2\n",
    "3) Load, on top of default pretrained config/weights.\n",
    "\n",
    "Steps 1) and 2) were done in the beginning of this notebook.\n",
    "\n",
    "Check https://github.com/facebookresearch/detectron2/blob/main/tools/convert-torchvision-to-d2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04b0c02-6e30-4080-ba2d-3ab6acd1b79c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg = get_detectron2_configuration(2, D2_iter_count)\n",
    "clear_output_folders(cfg.OUTPUT_DIR)\n",
    "\n",
    "cfg.MODEL.PIXEL_MEAN = [123.675, 116.280, 103.530]\n",
    "cfg.MODEL.PIXEL_STD = [58.395, 57.120, 57.375]\n",
    "cfg.MODEL.RESNETS.STRIDE_IN_1X1 = False\n",
    "cfg.INPUT.FORMAT = \"RGB\"\n",
    "\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "print(\"Loading weigths on top of existing config\")\n",
    "trainer.checkpointer.load(str(resnet_tv2D2_fname))\n",
    "trainer.train()\n",
    "evaluate_model_on_balloons(cfg, trainer)\n",
    "del trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f9c12e-9dfe-4244-8b5f-2da56ca4e060",
   "metadata": {},
   "source": [
    "## Finetune on top of lightly trained SSL model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcab0c9-da88-4909-8987-6e5c377fcf57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg = get_detectron2_configuration(2, D2_iter_count)\n",
    "clear_output_folders(cfg.OUTPUT_DIR)\n",
    "\n",
    "cfg.MODEL.PIXEL_MEAN = [123.675, 116.280, 103.530]\n",
    "cfg.MODEL.PIXEL_STD = [58.395, 57.120, 57.375]\n",
    "cfg.MODEL.RESNETS.STRIDE_IN_1X1 = False\n",
    "cfg.INPUT.FORMAT = \"RGB\"\n",
    "\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "print(\"Loading weigths on top of existing config\")\n",
    "trainer.checkpointer.load(str(MODELS_FOLDER / ResNet_light_ssl))\n",
    "trainer.train()\n",
    "evaluate_model_on_balloons(cfg, trainer)\n",
    "del trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae8161-d452-4482-9fb4-4c2e9141ad6a",
   "metadata": {},
   "source": [
    "## Finetune on top of heavy trained SSL model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2739c1d7-c356-450c-85e0-95fe2d9b31d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg = get_detectron2_configuration(2, D2_iter_count)\n",
    "clear_output_folders(cfg.OUTPUT_DIR)\n",
    "\n",
    "cfg.MODEL.PIXEL_MEAN = [123.675, 116.280, 103.530]\n",
    "cfg.MODEL.PIXEL_STD = [58.395, 57.120, 57.375]\n",
    "cfg.MODEL.RESNETS.STRIDE_IN_1X1 = False\n",
    "cfg.INPUT.FORMAT = \"RGB\"\n",
    "\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "print(\"Loading weigths on top of existing config\")\n",
    "trainer.checkpointer.load(str(MODELS_FOLDER / ResNet_large_ssl))\n",
    "trainer.train()\n",
    "evaluate_model_on_balloons(cfg, trainer)\n",
    "del trainer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
